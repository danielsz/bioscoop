#+TITLE: Bioscoop
#+SUBTITLE: Creative coding with video
#+OPTIONS: toc:1 num:nil
#+HTML_HEAD: <link rel="stylesheet" href="css/et-book.css" type="text/css" media="screen" />
#+HTML_HEAD: <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,400,600&display=swap" rel="stylesheet">
#+HTML_HEAD: <link rel="stylesheet" href="css/main.css" type="text/css" media="screen" />
#+HTML_HEAD: <link rel="stylesheet" href="css/post.css" type="text/css" media="screen" />
#+HTML_HEAD:  <script type="text/javascript" src="js/navigation.js"></script>

* Motivation

Historically, video editing has progressed from destructive
techniques, ie. cutting the negative, to non-destructive ones,
ie. non-linear editing. The latter has become possible due to film
being no longer analog but digital. In both cases, however, the
creative process is manual, or mouse-based. A different approach,
often overlooked, is programmatic: the editor spells out the edits he
wants to apply, and those are being carried out by an underlying
system.  FFmpeg is such a system; capable of carrying pretty much any
editing instruction you can think of.

FFmpeg is embedded in virtually every major platform and application
that handles media, yet its use in the creative coding community to
make video art is limited. Most video creators prefer to stay away
from the notoriously complex and error-prone string-based
syntax. Indeed, its usability is hindered by the information density
of its textual interface.

Bioscoop unleashes FFmpeg from its shackles and puts programmability
in the center of the creative process.

* AST convergence (internals)

The standout feature in terms of implementation and design is that
Bioscoop does both standalone compilation and macro expansion without
code duplication. Early in the project, after the grammar for the
language was defined, I realized that I didn't want to choose between
an internal or external DSL. I wanted both.

The project is structured around several key components:

*** *DSL Parser (=src/bioscoop/dsl.clj=)*
- Uses *Instaparse* to parse a Lisp-like syntax defined in =resources/lisp-grammar.bnf=
- Grammar allows for expressions like =(scale 1920 1080)= and =(let [width 1920] (scale width 1080))=
- Supports typical Lisp constructs: functions, let bindings, symbols, keywords, strings, numbers, booleans
- Transformation of the parse tree into internal representation
  
*** *Core Data Structures*
Three main records represent FFmpeg concepts:
- *Filter*: A single filter operation (e.g., scale, overlay, crop)
- *FilterChain*: A sequence of filters connected in series (comma-separated in FFmpeg)
- *FilterGraph*: Multiple filter chains running in parallel (semicolon-separated in FFmpeg)
  

*** *Domain Model (=src/bioscoop/domain/=)*
- Uses Clojure Spec to define the structure of filters, filter chains, and filtergraphs
- Provides validation for the core data structures

*** *Rendering Engine (=src/bioscoop/render.clj=)*
- Implements the =FFmpegRenderable= protocol to convert data structures to FFmpeg syntax
- Handles input/output labels for complex filtergraphs 
- Ensures proper escaping and formatting

*** Bidirectional Translation
- /src/bioscoop/render.clj/: Converts DSL → FFmpeg filtergraph strings
- /src/bioscoop/ffmpeg.clj/: Parses existing FFmpeg filtergraph strings → DSL structures


* The filtergraph

In FFmpeg, atomic editing operations—such as scaling, cropping,
blending, and color correction—are implemented as filters. With over
500 filters available, FFmpeg provides extensive transformation
capabilities.

When multiple filters are applied sequentially to source material,
they form a filterchain, written as comma-separated
commands. Filterchains can be labeled at their input and output
points, allowing one chain's output to serve as another's input. These
interconnected filterchains create a directed acyclic graph (DAG)
structure, which FFmpeg calls a filtergraph.  Filtergraphs are passed
to FFmpeg using the ~-filter_complex~ parameter.

That string-based syntax maps closely with the underlying ~libavfilter~
that parses it. What is happening is the following: the parser
(~libavfilter/graphparser.c~) tokenizes the string, identifying
individual filters, their parameters, and the connections between
them.

Each filter name in the string (like ~scale~, ~overlay~, ~colorkey~) maps to
a registered filter implementation in ~libavfilter~. FFmpeg looks up
these filters in its internal registry and instantiates them as
~AVFilterContext~ objects. Key-value pairs within each filter
specification are parsed and passed to the filter's initialization
function, which validates and stores them in the filter's private
context structure.

The parser creates an AVFilterGraph object and connects the
instantiated filters according to the semicolons (filterchain
boundaries) and labels in the string. Each connection becomes an
AVFilterLink that defines data flow between filter pads.

FFmpeg validates the complete graph topology, checking that
input/output pad counts match, media types are compatible (audio
vs. video), and that there are no cycles.

+ Filter names → AVFilter structs registered in libavfilter
+ Parameters (key=value) → Filter-specific configuration passed to
  AVFilter->init()
+ Filterchains (comma-separated) → Linked sequences of AVFilterContext nodes
+ Labels ([label]) → Named AVFilterLink references for graph routing
+ Semicolons → Graph branching points that create multiple parallel
  paths

This one-way translation from string to internal structures is the
core problem: there's no inverse mapping. Once parsed, the
~AVFilterGraph~ exists in memory, but there's no standardized way to
serialize it back or manipulate it programmatically before the string
parsing step. Developers must work in strings because ~libavfilter~'s
graph construction API, while programmatically accessible, is complex
and poorly documented compared to the string syntax.

The string format is essentially a convenience layer over
~libavfilter~'s C API—and it's become the /only/ practical interface,
despite its limitations.

This creates several challenges:

*No programmatic structure*: Unlike many modern tools that use JSON,
YAML, or object-based APIs, filtergraphs cannot be easily constructed,
validated, or manipulated programmatically. There's no schema to
reference, no type checking, and no ability to introspect the graph
structure before execution.

*String concatenation dependency*: Building dynamic filtergraphs
requires manual string concatenation, making the code fragile and
error-prone. A single misplaced comma, semicolon, or bracket can break
the entire pipeline, with errors only surfacing at runtime.

*Limited tooling support*: Because filtergraphs lack a formal
representation, IDEs cannot provide syntax highlighting,
auto-completion, or validation. Developers must memorize the syntax or
constantly reference documentation.

*Debugging difficulty*: When a filtergraph fails, error messages
reference the string position rather than logical components, making
it hard to identify which filter or connection caused the problem.

This string-only representation means filtergraphs are essentially
"write-only" code—difficult to read, maintain, and programmatically
generate at scale.

* Inspiration

#+begin_quote
The acts of the mind, wherein it exerts its power over simple ideas, are chiefly these three:

1. Combining several simple ideas into one compound one, and thus all
   complex ideas are made.

2. The second is bringing two ideas, whether simple or complex,
   together, and setting them by one another so as to take a view of
   them at once, without uniting them into one, by which it gets all
   its ideas of relations.

3. The third is separating them from all other ideas that accompany
   them in their real existence: this is called abstraction, and thus
   all its general ideas are made.

—John Locke, An Essay Concerning Human Understanding (1690)
#+end_quote
